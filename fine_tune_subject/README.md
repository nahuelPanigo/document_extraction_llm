# Fine-Tune Subject Classification

## Overview

This module implements subject classification for academic documents using various machine learning approaches. The system classifies documents into FORD (Fields of Research and Development) standardized categories.

## Recent Changes and Improvements

### 1. Dataset Expansion and Balancing
- **Switched from filtered to full dataset**: Migrated from `CSV_SEDICI_FILTERED` to `CSV_FORD_SUBJECTS`
- **Expanded from ~33 to 35+ classes** with significantly more samples per class
- **Implemented balanced dataset generation**: Up to 200 samples per class using `balance_dataset.py`
- **Added year-based filtering**: Removed documents older than 2019 for better text quality
- **Created comprehensive subject mapping**: Full SEDICI to FORD category normalization

### 2. Model Implementation and Comparison
- **Multiple model approaches implemented**:
  - `main.py`: Random Forest (baseline)
  - `main_svm.py`: Support Vector Machine with linear kernel
  - `main_xgboost.py`: XGBoost with class weighting
  - `main_embeddings.py`: Sentence transformers with centroid similarity
  - `main_subject_embeddings.py`: Subject-specific embeddings
  - `main_neural_torch.py`: PyTorch neural network on embeddings

### 3. Advanced Evaluation Framework
- **Created `model_comparison_framework.py`**: Unified testing system using Strategy pattern
- **Prevents data leakage**: Uses identical train/test splits as training
- **Comprehensive metrics**: Accuracy, Precision, Recall, F1-Score
- **Performance timing**: Model load time and per-sample prediction time
- **Production recommendations**: Speed vs accuracy trade-off analysis

### 4. Data Quality Improvements
- **XML/HTML tag cleanup**: `check_and_clean_xml_tags.py` removes `<h1>`, `<h2>`, `<p>` tags from extracted texts
- **Improved text extraction pipeline**: Better PDF to text conversion workflow
- **Quality filtering**: Removal of very short documents and better preprocessing

### 5. Configuration Centralization
- **Added new constants**: `CSV_FORD_SUBJECTS` for expanded dataset
- **Centralized model file naming**: All models save with consistent naming conventions
- **Environment configuration**: Updated `.env` for remote extractor service support

## Current Performance Results

Based on latest evaluation with expanded dataset:

| Model | Accuracy | F1-Score | Load Time | Prediction Time | Status |
|-------|----------|----------|-----------|-----------------|--------|
| SVM (Linear) | 82.32% | 79.43% | 0.21s | 53.0ms | âœ… Best Accuracy |
| Random Forest | 87.43% | 86.41% | 0.63s | 5.5ms | âœ… Good Balance |
| XGBoost | 85.68% | 85.06% | 0.19s | 5.4ms | âœ… Fastest |
| Embeddings | 54.62% | - | 5.32s | 0.0ms | âŒ Poor Performance |

## TODO

### âœ… COMPLETED: Major Refactoring & Unified System

#### 1. **Code Deduplication and Utilities** âœ…
- [x] **Create `utils/dataset/` module**:
  - [x] Move `create_dataset()` function from all mains to shared utility
  - [x] Centralize `load_csv_subjects()` function
  - [x] Create common preprocessing functions
  - [x] Implement shared train/test split logic with consistent random state
- [x] **Create `utils/models/` module**:
  - [x] Abstract base class for all model strategies
  - [x] Common model evaluation functions
  - [x] Shared metrics calculation utilities

#### 2. **Unified Main Entry Point** âœ…
- [x] **Create single `main_unified.py`**:
  - [x] Interactive interface for model selection (improved from CLI args)
  - [x] Options: SVM, XGBoost, Random Forest, Embeddings, Embeddings+KNN, Neural
  - [x] Integrate dataset utilities from step 1
  - [x] Remove duplicated code from individual main files
- [x] **Integrate pipeline steps**:
  - [x] Add download option to trigger PDF download for missing samples
  - [x] Add extract option to convert PDFs to text
  - [x] Add balance option to run dataset balancing
  - [x] Add clean option to remove XML/HTML tags
  - [x] **Pipeline runs ONCE at start, then model training loop**

#### 3. **Model Management** âœ…
- [x] **Create organized `models/` subdirectory structure**:
  - [x] `models/svm/` - SVM classifier files
  - [x] `models/xgboost/` - XGBoost classifier files
  - [x] `models/random_forest/` - Random Forest classifier files
  - [x] `models/embeddings/` - Embeddings classifier files
  - [x] `models/embeddings_knn/` - Embeddings+KNN classifier files
  - [x] `models/neural/` - PyTorch neural network files
- [x] **Add model constants to `constants.py`**:
  ```python
  SUBJECT_MODEL_FOLDER = ROOT_DIR / "fine_tune_subject/models"
  SUBJECT_MODEL_FOLDERS = {
      "svm": SUBJECT_MODEL_FOLDER / "svm",
      "xgboost": SUBJECT_MODEL_FOLDER / "xgboost", 
      "random_forest": SUBJECT_MODEL_FOLDER / "random_forest",
      "embeddings": SUBJECT_MODEL_FOLDER / "embeddings",
      "embeddings_knn": SUBJECT_MODEL_FOLDER / "embeddings_knn",
      "neural": SUBJECT_MODEL_FOLDER / "neural"
  }
  ```

#### 4. **Code Cleanup** âœ…
- [x] **Delete `analyze_model_performance.py`**:
  - [x] Functionality already integrated in `model_comparison_framework.py`
  - [x] Remove redundant analysis code
- [x] **Delete redundant `main_*.py` files**:
  - [x] All individual main files removed (only `main_unified.py` remains)
- [x] **Update all imports and references**:
  - [x] Fix paths after model folder reorganization
  - [x] Update constants usage across all files

### âœ… **Framework Compatibility** ðŸ› ï¸ - COMPLETED

#### 5. **Update `model_comparison_framework.py`** âœ…
- [x] Use `SUBJECT_MODEL_FOLDERS` constants instead of hardcoded paths
- [x] Import data loading functions from `utils/dataset/data_loader.py`
- [x] Update model file paths to use new organized structure
- [x] Test framework with new model organization
- [x] **NEW**: Fixed SVM model collision issue with separate folders

#### 6. **Address Science Class Confusion** âœ…
**Primary Issue**: "Ciencias fÃ­sicas" getting confused with related science classes

- [x] **Feature Engineering (HIGH IMPACT)** âœ…:
  ```python
  # âœ… IMPLEMENTED: Enhanced TF-IDF in SVM strategy
  vectorizer = TfidfVectorizer(
      max_features=50000,        # âœ… More vocabulary 
      ngram_range=(1, 4),        # âœ… Include 4-grams
      min_df=2,
      max_df=0.8,                # âœ… Lower for specific terms
      analyzer='word',           # âœ… Word-level analysis
      sublinear_tf=True,
      stop_words=SPANISH_STOP_WORDS  # âœ… Custom Spanish stop words (305 words)
  )
  ```

- [x] **Non-Linear SVM (MEDIUM IMPACT)** âœ…:
  ```python
  # âœ… IMPLEMENTED: RBF kernel SVM with separate model storage
  clf = SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced')
  ```
  
- [x] **Model Organization Enhancement** âœ…:
  - [x] Created separate folders for different SVM kernels:
    - `models/svm_linear/` for Linear SVM
    - `models/svm_rbf/` for RBF SVM
  - [x] Updated unified interface to show both SVM options
  - [x] Updated model comparison framework for both variants

### ðŸ”§ Current Priority Tasks

#### 7. **Advanced Science Class Improvements** ðŸ§ª

- [ ] **Targeted Data Augmentation (HIGH IMPACT)**:
  - [ ] Download 300-400 samples for confused classes:
    - `Ciencias fÃ­sicas` (main problem class)
    - `Ciencias quÃ­micas` 
    - `Ciencias biolÃ³gicas`
    - `Medicina bÃ¡sica`
    - `Ciencias de la salud`
  - [ ] Accept dataset imbalance for better class boundaries
  - [ ] Modify `balance_dataset.py` to target specific problem classes

- [ ] **Class Merging Strategy (STRATEGIC)**:
  - [ ] Consider merging very similar classes:
    - `Medicina bÃ¡sica` + `Ciencias de la salud` â†’ `Ciencias mÃ©dicas`
    - `Ciencias fÃ­sicas` + `Ciencias quÃ­micas` â†’ `Ciencias exactas`
  - [ ] Evaluate impact on overall accuracy

- [ ] **Domain-Specific Features**:
  - [ ] Create custom vocabulary for technical terms
  - [ ] Implement domain-specific stop words for Spanish academic text
  - [ ] Add character n-grams for technical terminology

#### 8. **Advanced Model Experiments** ðŸš€
- [x] **Try different kernel functions** for SVM âœ… (Linear + RBF implemented)
- [ ] **Hyperparameter optimization** using GridSearchCV
- [ ] **Ensemble methods** combining best-performing models
- [ ] **Spanish language models** for embeddings (BETO, RoBERTa-es)

### Documentation and Analysis

#### 7. **Jupyter Notebook Creation** ðŸ“Š
- [ ] **Create comprehensive analysis notebook**: `subject_classification_analysis.ipynb`
  - [ ] **Model Performance Comparison**:
    - [ ] Load results from `model_comparison_framework.py`
    - [ ] Generate comparison visualizations (accuracy, timing, confusion matrices)
    - [ ] Interactive plots for confusion matrix analysis
  - [ ] **Dataset Analysis**:
    - [ ] Class distribution before/after balancing
    - [ ] Text length statistics per class
    - [ ] Year distribution analysis
    - [ ] Sample quality assessment
  - [ ] **Feature Analysis**:
    - [ ] TF-IDF feature importance visualization
    - [ ] Word clouds for each subject category
    - [ ] N-gram analysis for confused classes
  - [ ] **Performance Evolution**:
    - [ ] Before/after dataset expansion results
    - [ ] Impact of different preprocessing steps
    - [ ] Timeline of improvements made
  - [ ] **Production Deployment Guide**:
    - [ ] Model selection recommendations
    - [ ] Performance benchmarks for different hardware
    - [ ] API integration examples
  - [ ] **Code References**:
    - [ ] Links to training scripts for each model
    - [ ] Configuration examples
    - [ ] Usage instructions for each component

## File Structure

```
fine_tune_subject/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ main_unified.py                    # âœ… Single entry point with interactive interface
â”œâ”€â”€ model_comparison_framework.py     # Model evaluation framework
â”œâ”€â”€ strategies/                       # âœ… Model training strategies
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ svm_strategy.py               # SVM training strategy
â”‚   â”œâ”€â”€ xgboost_strategy.py           # XGBoost training strategy
â”‚   â”œâ”€â”€ random_forest_strategy.py     # Random Forest training strategy
â”‚   â”œâ”€â”€ embeddings_strategy.py        # Embeddings training strategy
â”‚   â”œâ”€â”€ embeddings_knn_strategy.py    # Embeddings + KNN training strategy
â”‚   â””â”€â”€ neural_torch_strategy.py      # PyTorch neural network strategy
â”œâ”€â”€ utils/                            # âœ… Shared utilities
â”‚   â”œâ”€â”€ dataset/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py            # Centralized dataset loading
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_strategy.py          # Abstract strategy classes
â”‚       â”œâ”€â”€ evaluation.py             # Model evaluation utilities
â”‚       â””â”€â”€ training_strategy.py      # Training strategy base class
â”œâ”€â”€ models/                           # âœ… Organized model artifacts
â”‚   â”œâ”€â”€ svm_linear/                   # âœ… SVM Linear kernel (enhanced TF-IDF)
â”‚   â”‚   â”œâ”€â”€ svm_classifier.pkl
â”‚   â”‚   â”œâ”€â”€ svm_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ svm_label_encoder.pkl
â”‚   â”œâ”€â”€ svm_rbf/                      # âœ… SVM RBF kernel (non-linear)
â”‚   â”‚   â”œâ”€â”€ svm_classifier.pkl
â”‚   â”‚   â”œâ”€â”€ svm_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ svm_label_encoder.pkl
â”‚   â”œâ”€â”€ svm/                          # Legacy SVM folder (fallback)
â”‚   â”œâ”€â”€ xgboost/                      # XGBoost model files
â”‚   â”‚   â”œâ”€â”€ xgboost_classifier.pkl
â”‚   â”‚   â”œâ”€â”€ xgboost_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ xgboost_label_encoder.pkl
â”‚   â”œâ”€â”€ random_forest/                # Random Forest model files
â”‚   â”œâ”€â”€ embeddings/                   # Embeddings model files
â”‚   â”œâ”€â”€ embeddings_knn/               # Embeddings + KNN model files
â”‚   â”œâ”€â”€ neural/                       # Neural network model files
â”‚   â””â”€â”€ model_results/                # âœ… Model comparison results
â”‚       â”œâ”€â”€ model_comparison_svm_linear_xgboost.png
â”‚       â”œâ”€â”€ confusion_matrix_svm_linear.png
â”‚       â”œâ”€â”€ confusion_matrix_svm_rbf.png
â”‚       â””â”€â”€ confusion_matrix_xgboost.png
â”œâ”€â”€ balance_dataset.py               # Dataset balancing utility
â”œâ”€â”€ check_and_clean_xml_tags.py     # Text cleaning utility
â”œâ”€â”€ convert_pdfs_to_txt.py           # PDF to text conversion
â”œâ”€â”€ download_balance_pdfs.py         # PDF download utility
â”œâ”€â”€ create_ford_subjects_csv.py     # Dataset expansion utility
â””â”€â”€ subject_classification_analysis.ipynb  # [TODO] Analysis notebook
```

## Usage Examples

### Model Training
```bash
# âœ… NEW: Unified Interactive Interface (run from main tesis folder)
cd /home/nahuel/Documents/tesis
python3 -m fine_tune_subject.main_unified

# Interactive menu will guide you through:
# 1. Pipeline steps (download, extract, balance, clean) - runs ONCE
# 2. Model selection menu:
#    1. SVM (Linear)     - Enhanced TF-IDF, Spanish stop words
#    2. SVM (RBF)        - Non-linear kernel for complex boundaries  
#    3. XGBoost  
#    4. Random Forest
#    5. Embeddings (Centroid)
#    6. Embeddings + KNN
#    7. Neural Network (PyTorch)
#    8. Train All Models - Trains ALL models with separate storage
#    9. Exit
```

### Model Comparison
```bash
# Compare all available models
python3 -m fine_tune_subject.model_comparison_framework
> Models to test: all

# Compare specific models (use new SVM variants)
python3 -m fine_tune_subject.model_comparison_framework  
> Models to test: svm_linear,svm_rbf,xgboost

# Available model keys: svm_linear, svm_rbf, xgboost, random_forest, embeddings

# Results saved to: fine_tune_subject/models/model_results/
# - model_comparison_{models}.png (performance comparison charts)
# - confusion_matrix_{model}.png (individual confusion matrices)
```

### Dataset Management
```bash
# Expand dataset from full SEDICI
python3 -m fine_tune_subject.create_ford_subjects_csv

# Balance dataset for training
python3 -m fine_tune_subject.balance_dataset

# Clean extracted text
python3 -m fine_tune_subject.check_and_clean_xml_tags
```

## ðŸš€ Major Improvements Completed

### âœ… **LATEST**: Enhanced SVM Implementation & Results Management
- **Separate SVM Kernels**: Linear and RBF kernels now use dedicated folders to prevent model collisions
- **Enhanced TF-IDF Parameters**: 50k features, 4-grams, custom Spanish stop words (305 words) for better science class separation  
- **Framework Compatibility**: Updated model comparison framework with new folder structure
- **Unified Interface**: Both SVM variants available in interactive menu and comparison tools
- **Results Management**: Dedicated `model_results/` folder with model-specific filenames:
  - `model_comparison_{models}.png` for multi-model comparisons
  - `confusion_matrix_{model}.png` for individual confusion matrices

### âœ… Unified Training System
- **Single Entry Point**: `main_unified.py` with interactive interface
- **Strategy Pattern**: All models implemented as strategies for easy extension
- **Pipeline Integration**: All data processing steps integrated and run once at start
- **Clean Code**: Eliminated ~80% code duplication across training scripts

### âœ… Organized Model Management  
- **Structured Storage**: Each model type has its own subfolder
- **Centralized Constants**: All paths managed through `SUBJECT_MODEL_FOLDERS`
- **Automatic Directory Creation**: No manual folder setup required
- **Future-Proof**: Easy to add new model types

### âœ… Improved Architecture
- **Shared Utilities**: Common functions moved to `utils/dataset/` and `utils/models/`
- **Consistent Data Loading**: Single source of truth for dataset creation
- **Robust Error Handling**: Graceful failure with manual fallback instructions
- **Modular Design**: Each component can be used independently

### âœ… Developer Experience
- **Interactive Interface**: No command-line arguments to remember
- **Progress Feedback**: Clear status messages and error reporting  
- **Multiple Model Training**: Train all models with one command
- **Flexible Pipeline**: Choose which data processing steps to run

## Key Lessons Learned

1. **Data Quality > Quantity**: Cleaning HTML tags and filtering old documents improved results more than just adding samples
2. **Balanced Evaluation**: Proper train/test splits prevent inflated accuracy metrics
3. **Domain-Specific Challenges**: Academic subject classification requires specialized preprocessing for technical terminology
4. **Speed vs Accuracy Trade-offs**: SVM gives best accuracy (82%) but Random Forest offers good balance (87% accuracy, 10x faster)
5. **Class Similarity Issues**: Related scientific subjects need careful feature engineering or strategic merging

## Next Steps

1. **Complete refactoring tasks** to improve code maintainability
2. **Implement targeted improvements** for confused science classes  
3. **Create comprehensive analysis notebook** for better insights
4. **Deploy best-performing model** based on production requirements
5. **Consider ensemble approaches** combining multiple models for optimal performance