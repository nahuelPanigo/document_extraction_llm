# Tokens para autenticación entre servicios
EXTRACTOR_TOKEN=supersecret-extractor
LLM_LED_TOKEN=supersecret-led
LLM_DEEPANALYZE_TOKEN=supersecret-deep
ORCHESTRATOR_TOKEN=supersecret-orchestrator-token

# Endpoints internos de los servicios (usados por el orchestrator)
EXTRACTOR_URL=http://extractor_service:8001
LLM_LED_URL=http://llm_service_led:8002
LLM_DEEPANALYZE_URL=http://localhost:8003

IDENTIFIER_PATH_MODEL=models/modelo_tipo_documento.pkl
IDENTIFIER_PATH_VECTORIZER=models/vectorizador_tfidf.pkl

# Configuración para cada instancia de LLM
MODEL_SELECTED_SERVICE1=LED
MODEL_PATH_SERVICE1=models/fine-tuned-model-led  #only for huggingface models
MAX_TOKENS_INPUT_SERVICE1=2048  #only for huggingface models
MAX_TOKENS_OUTPUT_SERVICE1=1024  #only for huggingface models
TRUNACTION_SERVICE1=True #only for huggingface models
SPECIAL_TOKENS_TREATMENT_SERVICE1=True  #only for huggingface models
ERRORS_TREATMENT_SERVICE1=replace #only for huggingface models
QUANTIZATION_SERVICE1=False #only for huggingface models
IS_LOCAL_MODEL=True #only for huggingface models
IS_OLLAMA_MODEL=False # True for ollama models and False for huggingface models
OLLAMA_HOST_URL=http://localhost:11434  #only for ollama models