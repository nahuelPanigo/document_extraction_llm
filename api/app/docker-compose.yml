version: '3.8'

services:
  orchestrator:
    build:
      context: ./orchestrator
    container_name: orchestrator
    ports:
      - "8000:8000"
    environment:
      - SERVICE_TOKEN=${ORCHESTRATOR_TOKEN}
      - EXTRACTOR_TOKEN=${EXTRACTOR_TOKEN}
      - LLM_LED_TOKEN=${LLM_LED_TOKEN}
      - LLM_DEEPANALYZE_TOKEN=${LLM_DEEPANALYZE_TOKEN}
      - EXTRACTOR_URL=http://extractor_service:8001
      - LLM_LED_URL=http://llm_service_led:8002
      - LLM_DEEPANALYZE_URL=http://llm_service_qwen:8003
      - IDENTIFIER_PATH_MODEL=${IDENTIFIER_PATH_MODEL}
      - IDENTIFIER_PATH_VECTORIZER=${IDENTIFIER_PATH_VECTORIZER}
      - IDENTIFIER_PATH_LABEL_ENCODER=${IDENTIFIER_PATH_LABEL_ENCODER}
      - SUBJECT_IDENTIFIER_PATH_CLASSIFIER=${SUBJECT_IDENTIFIER_PATH_CLASSIFIER}
      - SUBJECT_IDENTIFIER_PATH_VECTORIZER=${SUBJECT_IDENTIFIER_PATH_VECTORIZER}
      - SUBJECT_IDENTIFIER_PATH_LABEL_ENCODER=${SUBJECT_IDENTIFIER_PATH_LABEL_ENCODER}
    depends_on:
      - extractor_service
      - llm_service_led

  extractor_service:
    build:
      context: ./extractor_service
    container_name: extractor_service
    ports:
      - "8001:8001"
    environment:
      - SERVICE_TOKEN=${EXTRACTOR_TOKEN}

  llm_service_led:
    build:
      context: ./llm_service
    container_name: llm_service_led
    ports:
      - "8002:8002"
    environment:
      - SERVICE_TOKEN=${LLM_LED_TOKEN}
      - IS_LOCAL_MODEL=${IS_LOCAL_MODEL1}
      - IS_OLLAMA_MODEL=${IS_OLLAMA_MODEL1}
      - MODEL_SELECTED=${MODEL_SELECTED_SERVICE1}
      - MODEL_PATH=${MODEL_PATH_SERVICE1}
      - MAX_TOKENS_INPUT=${MAX_TOKENS_INPUT_SERVICE1}
      - MAX_TOKENS_OUTPUT=${MAX_TOKENS_OUTPUT_SERVICE1}
      - TRUNACTION=${TRUNACTION_SERVICE1}
      - SPECIAL_TOKENS_TREATMENT=${SPECIAL_TOKENS_TREATMENT_SERVICE1}
      - ERRORS_TREATMENT=${ERRORS_TREATMENT_SERVICE1}
      - QUANTIZATION=${QUANTIZATION_SERVICE1}
    volumes:
      - ./models:/models

  llm_service_qwen:
    build:
      context: ./llm_service
    container_name: llm_service_qwen
    ports:
      - "8003:8003"
    environment:
      - SERVICE_PORT=8003
      - SERVICE_TOKEN=${LLM_DEEPANALYZE_TOKEN}
      - IS_LOCAL_MODEL=${IS_LOCAL_MODEL2}
      - IS_OLLAMA_MODEL=${IS_OLLAMA_MODEL2}
      - MODEL_SELECTED=${MODEL_SELECTED_SERVICE2}
      - OLLAMA_HOST_URL=${OLLAMA_HOST_URL}
    profiles:
      - qwen
